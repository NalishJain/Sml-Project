{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import hdbscan\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import LocalOutlierFactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "x = data.iloc[:, 1:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "x = np.array(x, dtype='float')\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective():\n",
    "    #performing kfold cross validation\n",
    "    num_folds = 5\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    cv_scores = []\n",
    "    model = LR(multi_class='ovr', solver='liblinear')\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(x):\n",
    "        x_train, y_train = x[train_idx], y[train_idx]\n",
    "        x_val, y_val = x[test_idx], y[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "        #performing dimensionality reduction\n",
    "        pca = PCA(n_components=375)\n",
    "        # pca = KernelPCA(n_components=300, kernel='rbf', gamma=15, random_state=42)\n",
    "\n",
    "        p = pca.fit(x_train)\n",
    "        x_train = p.transform(x_train)\n",
    "        x_val = p.transform(x_val)\n",
    "\n",
    "        #performing lda\n",
    "        lda = LDA(n_components=19)\n",
    "        l = lda.fit(x_train, y_train)\n",
    "\n",
    "        x_train = l.transform(x_train)\n",
    "        x_val = l.transform(x_val)\n",
    "        # Removing Outliers\n",
    "        # clf = LocalOutlierFactor(n_neighbors=5, contamination=0.1)\n",
    "        # ol = clf.fit_predict(x_train)\n",
    "        # indices = np.where(ol != -1)[0]\n",
    "        # x_train = x_train[indices]\n",
    "        # y_train = y_train[indices]\n",
    "        # isolation_forest = IsolationForest(n_estimators=500, contamination=0.1)\n",
    "        # isolation_forest.fit(x_train)\n",
    "        # indices = np.where(isolation_forest.predict(x_train) != -1)[0]\n",
    "        # x_train = x_train[indices]\n",
    "        # y_train = y_train[indices]\n",
    "\n",
    "        # #clustering\n",
    "        # clusterer1 = hdbscan.HDBSCAN(min_samples=1, min_cluster_size=5)\n",
    "        # clabels = clusterer1.fit_predict(x_train)\n",
    "        # print(set(clabels))\n",
    "        # print(list(set(clabels)))\n",
    "        # cluster_centroids = []\n",
    "\n",
    "        # for i in list(set(clabels)):\n",
    "        #     cluster_centroids.append(np.mean(x_train[clabels == i], axis=0))\n",
    "        # cluster_centroids = np.array(cluster_centroids, dtype='float')\n",
    "\n",
    "        # from sklearn.cluster import KMeans\n",
    "        # kmeans = KMeans(n_clusters=len(cluster_centroids), init=cluster_centroids , n_init = 1)\n",
    "        # kmeans1 = kmeans.fit(x_train)\n",
    "        # cluster_labels1 = kmeans1.predict(x_train)\n",
    "        # x_train = np.concatenate((x_train, cluster_labels1.reshape(-1, 1)), axis=1)\n",
    "        # cluster_labels2 = kmeans1.predict(x_val)\n",
    "        # x_val = np.concatenate((x_val, cluster_labels2.reshape(-1, 1)), axis=1)    \n",
    "        # kmeans = KMeans(n_clusters = 20, n_init= \"auto\")\n",
    "        # kmeans1 = kmeans.fit(x_train)\n",
    "        # cluster_labels1 = kmeans1.predict(x_train)\n",
    "        # x_train = np.concatenate((x_train, cluster_labels1.reshape(-1, 1)), axis=1)\n",
    "        # cluster_labels2 = kmeans1.predict(x_val)\n",
    "        # x_val = np.concatenate((x_val, cluster_labels2.reshape(-1, 1)), axis=1)\n",
    "        #fitting the model to the training data for this fold\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_val)\n",
    "        a = accuracy_score(y_val, y_pred)\n",
    "        cv_scores.append(a)\n",
    "        print(a)\n",
    "    # print(max_depth, max_features, min_samples_split, hdbscan_min_samples, hdbscan_min_cluster_size)\n",
    "    print('Cross-validation accuracy scores:', cv_scores)\n",
    "    print('Mean cross-validation accuracy:', np.mean(cv_scores))\n",
    "    print('Standard deviation of cross-validation accuracy:', np.std(cv_scores))\n",
    "    return (-np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7786885245901639\n",
      "0.7489711934156379\n",
      "0.8189300411522634\n",
      "0.8106995884773662\n",
      "0.8024691358024691\n",
      "Cross-validation accuracy scores: [0.7786885245901639, 0.7489711934156379, 0.8189300411522634, 0.8106995884773662, 0.8024691358024691]\n",
      "Mean cross-validation accuracy: 0.79195169668758\n",
      "Standard deviation of cross-validation accuracy: 0.025350212771285182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.79195169668758"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state= 42)\n",
    "numberofComp = np.arange(100, 610, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7786885245901639\n",
      "0.7950819672131147\n",
      "0.7827868852459017\n",
      "0.7991803278688525\n",
      "0.7704918032786885\n",
      "0.7745901639344263\n",
      "0.7622950819672131\n",
      "0.7786885245901639\n",
      "0.7745901639344263\n",
      "0.7827868852459017\n",
      "0.7950819672131147\n",
      "0.7909836065573771\n",
      "0.7950819672131147\n",
      "0.7950819672131147\n",
      "0.8032786885245902\n",
      "0.8032786885245902\n",
      "0.8114754098360656\n",
      "0.8032786885245902\n",
      "0.7991803278688525\n",
      "0.7991803278688525\n",
      "0.7991803278688525\n",
      "0.8155737704918032\n",
      "0.8114754098360656\n",
      "0.8073770491803278\n",
      "0.8155737704918032\n",
      "0.819672131147541\n",
      "0.8155737704918032\n",
      "0.819672131147541\n",
      "0.8114754098360656\n",
      "0.8319672131147541\n",
      "0.8114754098360656\n",
      "0.819672131147541\n",
      "0.8073770491803278\n",
      "0.8155737704918032\n",
      "0.8237704918032787\n",
      "0.8155737704918032\n",
      "0.8278688524590164\n",
      "0.8278688524590164\n",
      "0.8114754098360656\n",
      "0.819672131147541\n",
      "0.8278688524590164\n",
      "0.8073770491803278\n",
      "0.8032786885245902\n",
      "0.8073770491803278\n",
      "0.8114754098360656\n",
      "0.8073770491803278\n",
      "0.8032786885245902\n",
      "0.8032786885245902\n",
      "0.819672131147541\n",
      "0.8032786885245902\n",
      "0.8073770491803278\n"
     ]
    }
   ],
   "source": [
    "maxA = 0\n",
    "maxI = 0\n",
    "for i in numberofComp:\n",
    "        pca = PCA(n_components=i)\n",
    "        p = pca.fit(X_train)\n",
    "        x_train = p.transform(X_train)\n",
    "        x_val = p.transform(X_test)\n",
    "\n",
    "        #performing lda\n",
    "        lda = LDA(n_components=19)\n",
    "        l = lda.fit(x_train, y_train)\n",
    "\n",
    "        x_train = l.transform(x_train)\n",
    "        x_val = l.transform(x_val)\n",
    "        model = LR(max_iter=10000)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_val)\n",
    "        a = accuracy_score(y_test, y_pred)\n",
    "        if(a >= maxA):\n",
    "                maxA = a\n",
    "                maxI = i\n",
    "        print(a)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8319672131147541 390\n"
     ]
    }
   ],
   "source": [
    "print(maxA, maxI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>...</th>\n",
       "      <th>n4086</th>\n",
       "      <th>n4087</th>\n",
       "      <th>n4088</th>\n",
       "      <th>n4089</th>\n",
       "      <th>n4090</th>\n",
       "      <th>n4091</th>\n",
       "      <th>n4092</th>\n",
       "      <th>n4093</th>\n",
       "      <th>n4094</th>\n",
       "      <th>n4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.251257</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>0.042495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694072</td>\n",
       "      <td>1.146161</td>\n",
       "      <td>1.483842</td>\n",
       "      <td>0.717836</td>\n",
       "      <td>0.472616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191055</td>\n",
       "      <td>0.407350</td>\n",
       "      <td>0.441898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273436</td>\n",
       "      <td>1.466932</td>\n",
       "      <td>0.940850</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>1.032085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261903</td>\n",
       "      <td>0.992782</td>\n",
       "      <td>0.301102</td>\n",
       "      <td>0.636006</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.009448</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769983</td>\n",
       "      <td>0.834360</td>\n",
       "      <td>0.369656</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>0.431571</td>\n",
       "      <td>0.361993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.352401</td>\n",
       "      <td>0.346003</td>\n",
       "      <td>0.401412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339935</td>\n",
       "      <td>1.325595</td>\n",
       "      <td>0.981124</td>\n",
       "      <td>0.486731</td>\n",
       "      <td>0.747392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114281</td>\n",
       "      <td>0.696140</td>\n",
       "      <td>0.121505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093661</td>\n",
       "      <td>0.875113</td>\n",
       "      <td>0.360689</td>\n",
       "      <td>0.659230</td>\n",
       "      <td>0.546044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.835671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   n0        n1        n2        n3        n4        n5        n6  n7  \\\n",
       "0   0  0.0  0.000000  0.908889  0.251257  0.662262  0.042495  0.000000   0   \n",
       "1   1  0.0  0.000000  1.191055  0.407350  0.441898  0.000000  0.334858   0   \n",
       "2   2  0.0  0.261903  0.992782  0.301102  0.636006  0.009558  0.009448   0   \n",
       "3   3  0.0  0.000000  1.352401  0.346003  0.401412  0.000000  0.000000   0   \n",
       "4   4  0.0  0.000000  1.114281  0.696140  0.121505  0.000000  0.000000   0   \n",
       "\n",
       "         n8  ...     n4086     n4087     n4088     n4089     n4090     n4091  \\\n",
       "0  0.964784  ...  0.694072  1.146161  1.483842  0.717836  0.472616  0.000000   \n",
       "1  0.295357  ...  0.273436  1.466932  0.940850  0.470344  1.032085  0.000000   \n",
       "2  0.974949  ...  0.000000  0.769983  0.834360  0.369656  1.000858  0.431571   \n",
       "3  0.450667  ...  0.339935  1.325595  0.981124  0.486731  0.747392  0.000000   \n",
       "4  0.591384  ...  0.093661  0.875113  0.360689  0.659230  0.546044  0.000000   \n",
       "\n",
       "      n4092  n4093  n4094     n4095  \n",
       "0  0.488022    0.0    0.0  0.655670  \n",
       "1  0.654070    0.0    0.0  0.614493  \n",
       "2  0.361993    0.0    0.0  0.392158  \n",
       "3  0.300671    0.0    0.0  0.628365  \n",
       "4  0.427255    0.0    0.0  0.835671  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtt = X_train\n",
    "Ytt = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 1:-1].values\n",
    "xTest = testData.iloc[:, 1:].values\n",
    "xFeatures = np.array(x, dtype=float)\n",
    "xTest = np.array(xTest, dtype=float)\n",
    "xLabels = data.iloc[:, -1].values\n",
    "xLabels = np.array(xLabels)\n",
    "y_train = xLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=390)\n",
    "\n",
    "p = pca.fit(xFeatures)\n",
    "x_train = p.transform(xFeatures)\n",
    "x_val = p.transform(xTest)\n",
    "\n",
    "#performing lda\n",
    "lda = LDA(n_components=19)\n",
    "l = lda.fit(x_train, y_train)\n",
    "\n",
    "x_train = l.transform(x_train)\n",
    "x_val = l.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1094, 19)\n"
     ]
    }
   ],
   "source": [
    "# Removing Outliers\n",
    "# isolation_forest = IsolationForest(n_estimators=500, contamination=0.1)\n",
    "# isolation_forest.fit(x_train)\n",
    "# indices = np.where(isolation_forest.predict(x_train) != -1)[0]\n",
    "# x_train = x_train[indices]\n",
    "# y_train = y_train[indices]\n",
    "\n",
    "# clf = LocalOutlierFactor(n_neighbors=10, contamination=0.1)\n",
    "# ol = clf.fit_predict(x_train)\n",
    "# indices = np.where(ol != -1)[0]\n",
    "# x_train = x_train[indices]\n",
    "# y_train = y_train[indices]\n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, -1}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, -1]\n"
     ]
    }
   ],
   "source": [
    "# clusterer1 = hdbscan.HDBSCAN(min_samples=1, min_cluster_size=5)\n",
    "# clabels = clusterer1.fit_predict(x_train)\n",
    "# print(set(clabels))\n",
    "# print(list(set(clabels)))\n",
    "# cluster_centroids = []\n",
    "\n",
    "# for i in list(set(clabels)):\n",
    "#     cluster_centroids.append(np.mean(x_train[clabels == i], axis=0))\n",
    "# cluster_centroids = np.array(cluster_centroids, dtype='float')\n",
    "\n",
    "# from sklearn.cluster import KMeans\n",
    "# kmeans = KMeans(n_clusters=len(cluster_centroids), init=cluster_centroids , n_init = 1)\n",
    "# kmeans1 = kmeans.fit(x_train)\n",
    "# cluster_labels1 = kmeans1.predict(x_train)\n",
    "# x_train = np.concatenate((x_train, cluster_labels1.reshape(-1, 1)), axis=1)\n",
    "# cluster_labels2 = kmeans1.predict(x_val)\n",
    "# x_val = np.concatenate((x_val, cluster_labels2.reshape(-1, 1)), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters = 20, n_init= \"auto\")\n",
    "# kmeans1 = kmeans.fit(x_train)\n",
    "# cluster_labels1 = kmeans1.predict(x_train)\n",
    "# x_train = np.concatenate((x_train, cluster_labels1.reshape(-1, 1)), axis=1)\n",
    "# cluster_labels2 = kmeans1.predict(x_val)\n",
    "# x_val = np.concatenate((x_val, cluster_labels2.reshape(-1, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LR(max_iter=10000)\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(x_val)\n",
    "ids = range(415)\n",
    "results = pd.DataFrame({'ID': ids, 'Category': y_pred})\n",
    "results.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
